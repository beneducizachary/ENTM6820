---
title: "Statistics Homework"
author: "Zachary Beneduci"
date: "2023-04-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Question 1

Please describe the data you are using for your project in a couple sentences. What type of data is it and what does it look like? What are the objectives and hypotheses of your project? How do you plan to test this hypothesis (what types of statistics)?

The data were collected from three experimental plots established at the E.V. Smith research center in Shorter, AL. In each plot (named BEU1, FCU1, and PBU1), 16 subplots of 42 x 24 ft^2 were planted with a 20 species wildflower seed mix in spring 2022. Subplots were assigned to four groups (mowing, light-disking, their combination, and control) balanced within and across fields. These treatments were applied in fall 2022. Pre-treatment wildflower counts were collected six times (rounds) throughout the 2022 field season in each subplot from 10 randomly placed 1.25 x 0.8 m^2 quadrats. The objective of the project is to determine the effect of mowing, disking, and the combination on wildflower density, diversity, and community composition. For this assignment, I'll test the hypothesis that wildflower density does not differ between treatments and the control (which we would hope for, since the treatments were not applied yet!). To do this, I will consider several variations of linear models to compare differences between each treatment to the control group. Therefore, beta estimates from regression and their associated measures of precision, will be assessed.

#### Question 2

Load the dataset:

```{r}
datum1 <- read.csv("https://raw.githubusercontent.com/beneducizachary/ENTM6820/main/ReproducibleWorkflow/Data/BMPvegDataRawZB7.csv")

str(datum1)
```

Load necessary packages:

```{r}
#install.packages("tidyverse")
library(tidyverse)
```

The first step is to format the dataset. It contains a number of other measurements, mostly counts from volunteer flower species.

Note: Site and Plot (as referred to above) are synonymous.

```{r}
datum2 <- datum1 %>%
  # Select relevant grouping variables and the planted species with counts > 0.
  select(Date, Round, Site, Subplot, Quadrat, ASTU, COTI3, CHFA2, DRAM, GAPU, HEAN2, MOPU, RUHI2) %>%
  # Filter out sampling rounds 'a' and 'b'. There were no planted wildflowers.
  filter(Round == "c"|Round == "d"|Round == "e"|Round == "f") %>%
  # Making sure counts are considered numbers.
  mutate_at(c(6:13), as.numeric) %>%
  # Replacing the empty cells filled with NAs by R with zeros.
  mutate_at(c(6:13), ~replace_na(.,0)) %>%
  # Switch to long format for calculations.
  pivot_longer(cols = ASTU:RUHI2, names_to = "Species", values_to = "Count") %>%
  # Specify variables to group by for calculations.
  group_by(Site, Round, Subplot, Species) %>%
  # Summing counts for wildflowers across the 10 quadrats per subplot.
  summarise(Count=sum(Count)) %>%
  # Switch back to wide.
  pivot_wider(names_from = Species, values_from = Count) %>%
  # Specify we want next calculations applied across columns.
  rowwise() %>%
  mutate(
    TotalDens = sum(c_across(ASTU:RUHI2)), # Sums all counts across columns.
    Richness = sum(c_across(ASTU:RUHI2)!=0) # Counts the frequency of values >0.
  ) %>%
  # Assign subplots to columns and rows within fields for spatial visualization.
  mutate(Row = 
           case_when(between(Subplot, 1, 4)~1,
                     between(Subplot, 5, 8)~2,
                     between(Subplot, 8, 12)~3,
                     between(Subplot, 13, 16)~4)) %>%
  mutate(Col = 
           case_when(Subplot == 4 | Subplot == 8 | Subplot == 12 | Subplot == 16 ~ 1,
                     Subplot == 3 | Subplot == 7 | Subplot == 11 | Subplot == 15 ~ 2,
                     Subplot == 2 | Subplot == 6 | Subplot == 10 | Subplot == 14 ~ 3,
                     Subplot == 1 | Subplot == 5 | Subplot == 9 | Subplot == 13 ~ 4)) %>%
  # Finally, we'll add the treatment information.
  mutate(Treatment =
           case_when(Subplot == 1 & Site == "FCU1" ~ "Disking",
                     Subplot == 2 & Site == "FCU1" ~ "Mowing",
                     Subplot == 3 & Site == "FCU1" ~ "Combo",
                     Subplot == 4 & Site == "FCU1" ~ "Control",
                     Subplot == 5 & Site == "FCU1" ~ "Mowing",
                     Subplot == 6 & Site == "FCU1" ~ "Control",
                     Subplot == 7 & Site == "FCU1" ~ "Disking",
                     Subplot == 8 & Site == "FCU1" ~ "Combo",
                     Subplot == 9 & Site == "FCU1" ~ "Combo",
                     Subplot == 10 & Site == "FCU1" ~ "Disking",
                     Subplot == 11 & Site == "FCU1" ~ "Mowing",
                     Subplot == 12 & Site == "FCU1" ~ "Control",
                     Subplot == 13 & Site == "FCU1" ~ "Control",
                     Subplot == 14 & Site == "FCU1" ~ "Mowing",
                     Subplot == 15 & Site == "FCU1" ~ "Combo",
                     Subplot == 16 & Site == "FCU1" ~ "Disking",
                     Subplot == 1 & Site == "BEU1" ~ "Combo",
                     Subplot == 2 & Site == "BEU1" ~ "Disking",
                     Subplot == 3 & Site == "BEU1" ~ "Mowing",
                     Subplot == 4 & Site == "BEU1" ~ "Control",
                     Subplot == 5 & Site == "BEU1" ~ "Mowing",
                     Subplot == 6 & Site == "BEU1" ~ "Control",
                     Subplot == 7 & Site == "BEU1" ~ "Combo",
                     Subplot == 8 & Site == "BEU1" ~ "Disking",
                     Subplot == 9 & Site == "BEU1" ~ "Disking",
                     Subplot == 10 & Site == "BEU1" ~ "Mowing",
                     Subplot == 11 & Site == "BEU1" ~ "Control",
                     Subplot == 12 & Site == "BEU1" ~ "Combo",
                     Subplot == 13 & Site == "BEU1" ~ "Control",
                     Subplot == 14 & Site == "BEU1" ~ "Combo",
                     Subplot == 15 & Site == "BEU1" ~ "Disking",
                     Subplot == 16 & Site == "BEU1" ~ "Mowing",
                     Subplot == 1 & Site == "PBU1" ~ "Mowing",
                     Subplot == 2 & Site == "PBU1" ~ "Disking",
                     Subplot == 3 & Site == "PBU1" ~ "Combo",
                     Subplot == 4 & Site == "PBU1" ~ "Control",
                     Subplot == 5 & Site == "PBU1" ~ "Control",
                     Subplot == 6 & Site == "PBU1" ~ "Combo",
                     Subplot == 7 & Site == "PBU1" ~ "Mowing",
                     Subplot == 8 & Site == "PBU1" ~ "Disking",
                     Subplot == 9 & Site == "PBU1" ~ "Disking",
                     Subplot == 10 & Site == "PBU1" ~ "Mowing",
                     Subplot == 11 & Site == "PBU1" ~ "Combo",
                     Subplot == 12 & Site == "PBU1" ~ "Control",
                     Subplot == 13 & Site == "PBU1" ~ "Disking",
                     Subplot == 14 & Site == "PBU1" ~ "Combo",
                     Subplot == 15 & Site == "PBU1" ~ "Control",
                     Subplot == 16 & Site == "PBU1" ~ "Mowing")) %>%
  # Set treatment as a factor.
  mutate_at(c(16), as.factor) %>%
  # Relevel the Treatment variable so Control is the reference group.
  mutate(Treatment = relevel(Treatment, "Control")) %>%
  # Set Subplot variable as a factor for random effects.
  mutate_at(c(3), as.factor)
```
Our response variable is named TotalDens. It is the density of wildflower floral units within 10 m^2 for each Site x Subplot x Round combination.

Visualize the data:

Overall density:
```{r}
ggplot(datum2, aes(x = Treatment, y = TotalDens)) +
  geom_boxplot()
```

By Site:

```{r}
ggplot(datum2, aes(x = Treatment, y = TotalDens)) +
  geom_boxplot() +
  facet_wrap(~Site)
```

By Round:

```{r}
ggplot(datum2, aes(x = Treatment, y = TotalDens)) +
  geom_boxplot() +
  facet_wrap(~Round)
```

By Site*Round:

```{r}
ggplot(datum2, aes(x = Treatment, y = TotalDens)) +
  geom_boxplot() +
  facet_wrap(~Site*Round)
```

Looks like there is an effect of Site and Round. Of note is that boxplots are pulled towards zero, suggesting zero inflation.


Finally, look at the distribution:

```{r}
ggplot(datum2, aes(x = TotalDens)) +
  geom_histogram(bins = 140)
```

Our response is at least non-Gaussian. Hard to tell if the residuals are without modeling.

Of note is that subplots were sampled four times throughout the 2022 season. For the Treatment effects (of interest here), we would commit pseudoreplication if each time point is treated as an independent measurement. Additionally, subplots at the same site are not independent, so we'll need to
account for this as well.

Start with a general linear model:

```{r}
lm1 <- lm(TotalDens ~ Treatment, datum2)
summary(lm1)
```

Looking at the model estimates, we can see slight differences in effect size between treatment groups. However, variation is high and none of these effects are considered significant. While we are not seeing the consequence here, running such a model could lead to inflated type I error rates, as samples from the sample plots were taken throughout the year.

```{r}
plot(residuals(lm1))
```

The residuals are quite messy. More points are concentrated below zero,
and those above zero are typcically higher. Additionally, the residuals
are heteroscedastic.

Correct pseudoreplication with a linear mixed model:

```{r}
#install.packages("lme4)
library(lme4)

lmm <- lmer(TotalDens~Treatment + (1|Site/Subplot), datum2, REML = TRUE)
summary(lmm)
```
```{r}
plot(residuals(lmm))
```


Didn't help the residuals much. However, it is correctly identifying that there are 3 sites and 48 subplots. The previous lm assumed that there were 192 subplots. We do have singular fit, which is expected when estimating random effects with 3 levels for Site and 4 levels for Subplot. Here, I opt to keep it to avoid pseudoreplication. Moreover, a recent paper showed that including random effects with few levels to specify nesting can only help hypothesis tests.

Clearly the residuals are off, so let's find a better error family:

```{r}
#install.packages("glmmTMB")
#install.packages("DHARMa")
library(glmmTMB) # A useful package for fitting generalized linear mixed models.
library(DHARMa) # A package of diagnostic functions for such models.
```

Try poisson:

```{r}
pois <- glmmTMB(TotalDens ~ Treatment + (1|Site/Subplot), datum2,
                family = poisson)
summary(pois)
```
```{r}
plot(simulateResiduals(fittedModel = pois))
```

Negative binomial:

```{r}
nb <- glmmTMB(TotalDens ~ Treatment + (1|Site/Subplot), datum2,
                 family = nbinom2)
summary(nb)
```
```{r}
plot(simulateResiduals(fittedModel = nb))
```

Zero-inflated poisson:

```{r}
zip <- glmmTMB(TotalDens ~ Treatment + (1|Site/Subplot), datum2,
                family = poisson, ziformula = ~1)
summary(zip)
```
```{r}
plot(simulateResiduals(fittedModel = zip))
```

Zero-inflated negative binomial:

```{r}
zinb <- glmmTMB(TotalDens ~ Treatment + (1|Site/Subplot), datum2,
                family = nbinom2, ziformula = ~1)
summary(zinb)
```
```{r}
plot(simulateResiduals(fittedModel = zinb))
```

Inspecting the DHARMa residual plots shows that the negative binomial and its zero-inflated counterpart fit far better than both poisson models. The regular negative binomial looks best, as the model complexity added by the zero inflated portion doesn't provide much improvement.

Can also inspect the AIC score for a measure of model fit:

```{r}
anova(pois, nb, zip, zinb)
```

The classic negative binomial has the lowest AIC, although the delta AIC between the nb and zinb is exact 2. This would warrant considering both models as well supported, as a penalty is added to the AIC score for number of parameters, so the AIC score will rise slightly by estimating the intercept of the zero-inflation side of the model.

I'll opt for the more parsimonious model, the nb, rather than the more complex zinb. Additionally, the estimates don't change between the two.

We can also compare the nb with and without random effects.

First fit a model without random effects:

```{r}
nb2 <- glmmTMB(TotalDens ~ Treatment, datum2, family = nbinom2)
summary(nb2)
```
```{r}
plot(simulateResiduals(fittedModel = nb2))
```

Now compare:

```{r}
anova(nb2, nb)
```

And we get a better fit with the random effects.

For our best model, we'll fit with restricted maximum likelihood, which is more appropriate for small sample sizes.

```{r}
nb3 <- glmmTMB(TotalDens ~ Treatment + (1|Site/Subplot), datum2,
                 family = nbinom2, REML = TRUE)
summary(nb3)
```

Let's tidy up the information:

```{r}
#install.packages("broom.mixed")
library(broom.mixed)

nb3 %>%
  broom.mixed::tidy() %>%
  select(effect, term, estimate, std.error, statistic, p.value)
```

And get the marginal means:
```{r}
#install.packages("emmeans")
library(emmeans)

nb3 %>%
  emmeans("Treatment", type = "response")
```
#### Question 3

There are no significant differences between any of the groups. Although the effect size of the subplots assigned to mowing are slightly higher before any of the treatments were applied.

There is high variation for these faux-effects, leading to low confidence in estimates. I'm not too surprised, as there is a lot of variation across subplots. This preliminary analysis suggests that there would need to be quite a large difference in effect size between treatments and control to detect an effect, which is slightly worrisome. I'm flirting with trying a spatial autocorrelation model (possibly from package spaMM) or trying a random slopes model once my post-treatment data come in after this field season. I'm not sure how data hungry both of these approaches will be. Looking at tile plots shows a lot of variation across subplots in the same plot, so assessing spatial autocorrelation may make the most sense.

For sharing these results, an effects plot of the marginal means and their precision from the nb model seems most appropriate. This could also be presented in a table, as there are not many coefficients being estimated. Additionally, an AIC table of the models considered would be good to support model choice.

I am planning to present a pre-treatment analysis for wildflower diversity and community composition. My plan is to use package iNEXT for rarefaction of effective number of species based on hill numbers and permanova results, respectively. Still figuring out that code.